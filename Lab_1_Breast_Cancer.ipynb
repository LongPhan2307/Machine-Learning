{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 1_Breast Cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSzzc14j/6hNway2EEk3zq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LongPhan2307/Machine-Learning/blob/main/Lab_1_Breast_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsz1OMphD39R",
        "outputId": "6cefdc59-9adc-4f6b-bf92-307500d15b81",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5a87f2b-ca0b-4de3-acc9-54346bb6fd52\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5a87f2b-ca0b-4de3-acc9-54346bb6fd52\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving breast-cancer.data to breast-cancer.data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIz6ynEBWJwj",
        "outputId": "6461a745-8718-43e7-98db-e8436488027b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpwFrSp6WUXw",
        "outputId": "53ff1fd5-2809-4275-e1ff-622cddcdf2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " breast-cancer.data\t knn_dt_rf.ipynb\t     'Lab 1_Lung Cancer.ipynb'\n",
            " DBScanAlgorithm.ipynb\t'Lab 1_Breast Cancer.ipynb'   lung-cancer.data\n",
            "'Decision Tree.ipynb'\t'Lab 1_Face Images.ipynb'\n",
            " iris.data\t\t'Lab1_Iris Dataset.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JITze4OjW1lT",
        "outputId": "4b70edd9-cfe8-49dd-a953-850b0aa2fee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import shutil\n",
        "from collections import namedtuple\n",
        "from os import environ, listdir, makedirs\n",
        "from os.path import dirname, exists, expanduser, isdir, join, splitext\n",
        "import hashlib\n",
        "\n",
        "from ..utils import Bunch\n",
        "from ..utils import check_random_state\n",
        "from ..utils import check_pandas_support\n",
        "from ..utils.validation import _deprecate_positional_args\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "RemoteFileMetadata = namedtuple('RemoteFileMetadata',\n",
        "                                ['filename', 'url', 'checksum'])\n",
        "\n",
        "\n",
        "def get_data_home(data_home=None):\n",
        "    \"\"\"Return the path of the scikit-learn data dir.\n",
        "    This folder is used by some large dataset loaders to avoid downloading the\n",
        "    data several times.\n",
        "    By default the data dir is set to a folder named 'scikit_learn_data' in the\n",
        "    user home folder.\n",
        "    Alternatively, it can be set by the 'SCIKIT_LEARN_DATA' environment\n",
        "    variable or programmatically by giving an explicit folder path. The '~'\n",
        "    symbol is expanded to the user home folder.\n",
        "    If the folder does not already exist, it is automatically created.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_home : str | None\n",
        "        The path to scikit-learn data dir.\n",
        "    \"\"\"\n",
        "    if data_home is None:\n",
        "        data_home = environ.get('SCIKIT_LEARN_DATA',\n",
        "                                join('~', 'scikit_learn_data'))\n",
        "    data_home = expanduser(data_home)\n",
        "    if not exists(data_home):\n",
        "        makedirs(data_home)\n",
        "    return data_home\n",
        "\n",
        "\n",
        "def clear_data_home(data_home=None):\n",
        "    \"\"\"Delete all the content of the data home cache.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_home : str | None\n",
        "        The path to scikit-learn data dir.\n",
        "    \"\"\"\n",
        "    data_home = get_data_home(data_home)\n",
        "    shutil.rmtree(data_home)\n",
        "\n",
        "\n",
        "def _convert_data_dataframe(caller_name, data, target,\n",
        "                            feature_names, target_names):\n",
        "    pd = check_pandas_support('{} with as_frame=True'.format(caller_name))\n",
        "    data_df = pd.DataFrame(data, columns=feature_names)\n",
        "    target_df = pd.DataFrame(target, columns=target_names)\n",
        "    combined_df = pd.concat([data_df, target_df], axis=1)\n",
        "    X = combined_df[feature_names]\n",
        "    y = combined_df[target_names]\n",
        "    if y.shape[1] == 1:\n",
        "        y = y.iloc[:, 0]\n",
        "    return combined_df, X, y\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_files(container_path, *, description=None, categories=None,\n",
        "               load_content=True, shuffle=True, encoding=None,\n",
        "               decode_error='strict', random_state=0):\n",
        "    \"\"\"Load text files with categories as subfolder names.\n",
        "    Individual samples are assumed to be files stored a two levels folder\n",
        "    structure such as the following:\n",
        "        container_folder/\n",
        "            category_1_folder/\n",
        "                file_1.txt\n",
        "                file_2.txt\n",
        "                ...\n",
        "                file_42.txt\n",
        "            category_2_folder/\n",
        "                file_43.txt\n",
        "                file_44.txt\n",
        "                ...\n",
        "    The folder names are used as supervised signal label names. The individual\n",
        "    file names are not important.\n",
        "    This function does not try to extract features into a numpy array or scipy\n",
        "    sparse matrix. In addition, if load_content is false it does not try to\n",
        "    load the files in memory.\n",
        "    To use text files in a scikit-learn classification or clustering algorithm,\n",
        "    you will need to use the :mod`~sklearn.feature_extraction.text` module to\n",
        "    build a feature extraction transformer that suits your problem.\n",
        "    If you set load_content=True, you should also specify the encoding of the\n",
        "    text using the 'encoding' parameter. For many modern text files, 'utf-8'\n",
        "    will be the correct encoding. If you leave encoding equal to None, then the\n",
        "    content will be made of bytes instead of Unicode, and you will not be able\n",
        "    to use most functions in :mod:`~sklearn.feature_extraction.text`.\n",
        "    Similar feature extractors should be built for other kind of unstructured\n",
        "    data input such as images, audio, video, ...\n",
        "    Read more in the :ref:`User Guide <datasets>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    container_path : string or unicode\n",
        "        Path to the main folder holding one subfolder per category\n",
        "    description : string or unicode, optional (default=None)\n",
        "        A paragraph describing the characteristic of the dataset: its source,\n",
        "        reference, etc.\n",
        "    categories : A collection of strings or None, optional (default=None)\n",
        "        If None (default), load all the categories. If not None, list of\n",
        "        category names to load (other categories ignored).\n",
        "    load_content : bool, optional (default=True)\n",
        "        Whether to load or not the content of the different files. If true a\n",
        "        'data' attribute containing the text information is present in the data\n",
        "        structure returned. If not, a filenames attribute gives the path to the\n",
        "        files.\n",
        "    shuffle : bool, optional (default=True)\n",
        "        Whether or not to shuffle the data: might be important for models that\n",
        "        make the assumption that the samples are independent and identically\n",
        "        distributed (i.i.d.), such as stochastic gradient descent.\n",
        "    encoding : string or None (default is None)\n",
        "        If None, do not try to decode the content of the files (e.g. for images\n",
        "        or other non-text content). If not None, encoding to use to decode text\n",
        "        files to Unicode if load_content is True.\n",
        "    decode_error : {'strict', 'ignore', 'replace'}, optional\n",
        "        Instruction on what to do if a byte sequence is given to analyze that\n",
        "        contains characters not of the given `encoding`. Passed as keyword\n",
        "        argument 'errors' to bytes.decode.\n",
        "    random_state : int, RandomState instance or None, default=0\n",
        "        Determines random number generation for dataset shuffling. Pass an int\n",
        "        for reproducible output across multiple function calls.\n",
        "        See :term:`Glossary <random_state>`.\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : list of str\n",
        "            Only present when `load_content=True`.\n",
        "            The raw text data to learn.\n",
        "        target : ndarray\n",
        "            The target labels (integer index).\n",
        "        target_names : list\n",
        "            The names of target classes.\n",
        "        DESCR : str\n",
        "            The full description of the dataset.\n",
        "        filenames: ndarray\n",
        "            The filenames holding the dataset.\n",
        "    \"\"\"\n",
        "    target = []\n",
        "    target_names = []\n",
        "    filenames = []\n",
        "\n",
        "    folders = [f for f in sorted(listdir(container_path))\n",
        "               if isdir(join(container_path, f))]\n",
        "\n",
        "    if categories is not None:\n",
        "        folders = [f for f in folders if f in categories]\n",
        "\n",
        "    for label, folder in enumerate(folders):\n",
        "        target_names.append(folder)\n",
        "        folder_path = join(container_path, folder)\n",
        "        documents = [join(folder_path, d)\n",
        "                     for d in sorted(listdir(folder_path))]\n",
        "        target.extend(len(documents) * [label])\n",
        "        filenames.extend(documents)\n",
        "\n",
        "    # convert to array for fancy indexing\n",
        "    filenames = np.array(filenames)\n",
        "    target = np.array(target)\n",
        "\n",
        "    if shuffle:\n",
        "        random_state = check_random_state(random_state)\n",
        "        indices = np.arange(filenames.shape[0])\n",
        "        random_state.shuffle(indices)\n",
        "        filenames = filenames[indices]\n",
        "        target = target[indices]\n",
        "\n",
        "    if load_content:\n",
        "        data = []\n",
        "        for filename in filenames:\n",
        "            with open(filename, 'rb') as f:\n",
        "                data.append(f.read())\n",
        "        if encoding is not None:\n",
        "            data = [d.decode(encoding, decode_error) for d in data]\n",
        "        return Bunch(data=data,\n",
        "                     filenames=filenames,\n",
        "                     target_names=target_names,\n",
        "                     target=target,\n",
        "                     DESCR=description)\n",
        "\n",
        "    return Bunch(filenames=filenames,\n",
        "                 target_names=target_names,\n",
        "                 target=target,\n",
        "                 DESCR=description)\n",
        "\n",
        "\n",
        "def load_data(module_path, data_file_name):\n",
        "    \"\"\"Loads data from module_path/data/data_file_name.\n",
        "    Parameters\n",
        "    ----------\n",
        "    module_path : string\n",
        "        The module path.\n",
        "    data_file_name : string\n",
        "        Name of csv file to be loaded from\n",
        "        module_path/data/data_file_name. For example 'wine_data.csv'.\n",
        "    Returns\n",
        "    -------\n",
        "    data : Numpy array\n",
        "        A 2D array with each row representing one sample and each column\n",
        "        representing the features of a given sample.\n",
        "    target : Numpy array\n",
        "        A 1D array holding target variables for all the samples in `data.\n",
        "        For example target[0] is the target varible for data[0].\n",
        "    target_names : Numpy array\n",
        "        A 1D array containing the names of the classifications. For example\n",
        "        target_names[0] is the name of the target[0] class.\n",
        "    \"\"\"\n",
        "    with open(join(module_path, 'data', data_file_name)) as csv_file:\n",
        "        data_file = csv.reader(csv_file)\n",
        "        temp = next(data_file)\n",
        "        n_samples = int(temp[0])\n",
        "        n_features = int(temp[1])\n",
        "        target_names = np.array(temp[2:])\n",
        "        data = np.empty((n_samples, n_features))\n",
        "        target = np.empty((n_samples,), dtype=np.int)\n",
        "\n",
        "        for i, ir in enumerate(data_file):\n",
        "            data[i] = np.asarray(ir[:-1], dtype=np.float64)\n",
        "            target[i] = np.asarray(ir[-1], dtype=np.int)\n",
        "\n",
        "    return data, target, target_names\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_wine(*, return_X_y=False, as_frame=False):\n",
        "    \"\"\"Load and return the wine dataset (classification).\n",
        "    .. versionadded:: 0.18\n",
        "    The wine dataset is a classic and very easy multi-class classification\n",
        "    dataset.\n",
        "    =================   ==============\n",
        "    Classes                          3\n",
        "    Samples per class        [59,71,48]\n",
        "    Samples total                  178\n",
        "    Dimensionality                  13\n",
        "    Features            real, positive\n",
        "    =================   ==============\n",
        "    Read more in the :ref:`User Guide <wine_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    return_X_y : bool, default=False.\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
        "        See below for more information about the `data` and `target` object.\n",
        "    as_frame : bool, default=False\n",
        "        If True, the data is a pandas DataFrame including columns with\n",
        "        appropriate dtypes (numeric). The target is\n",
        "        a pandas DataFrame or Series depending on the number of target columns.\n",
        "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
        "        DataFrames or Series as described below.\n",
        "        .. versionadded:: 0.23\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : {ndarray, dataframe} of shape (178, 13)\n",
        "            The data matrix. If `as_frame=True`, `data` will be a pandas\n",
        "            DataFrame.\n",
        "        target: {ndarray, Series} of shape (178,)\n",
        "            The classification target. If `as_frame=True`, `target` will be\n",
        "            a pandas Series.\n",
        "        feature_names: list\n",
        "            The names of the dataset columns.\n",
        "        target_names: list\n",
        "            The names of target classes.\n",
        "        frame: DataFrame of shape (178, 14)\n",
        "            Only present when `as_frame=True`. DataFrame with `data` and\n",
        "            `target`.\n",
        "            .. versionadded:: 0.23\n",
        "        DESCR: str\n",
        "            The full description of the dataset.\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "    The copy of UCI ML Wine Data Set dataset is downloaded and modified to fit\n",
        "    standard format from:\n",
        "    https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
        "    Examples\n",
        "    --------\n",
        "    Let's say you are interested in the samples 10, 80, and 140, and want to\n",
        "    know their class name.\n",
        "    >>> from sklearn.datasets import load_wine\n",
        "    >>> data = load_wine()\n",
        "    >>> data.target[[10, 80, 140]]\n",
        "    array([0, 1, 2])\n",
        "    >>> list(data.target_names)\n",
        "    ['class_0', 'class_1', 'class_2']\n",
        "    \"\"\"\n",
        "    module_path = dirname(__file__)\n",
        "    data, target, target_names = load_data(module_path, 'wine_data.csv')\n",
        "\n",
        "    with open(join(module_path, 'descr', 'wine_data.rst')) as rst_file:\n",
        "        fdescr = rst_file.read()\n",
        "\n",
        "    feature_names = ['alcohol',\n",
        "                     'malic_acid',\n",
        "                     'ash',\n",
        "                     'alcalinity_of_ash',\n",
        "                     'magnesium',\n",
        "                     'total_phenols',\n",
        "                     'flavanoids',\n",
        "                     'nonflavanoid_phenols',\n",
        "                     'proanthocyanins',\n",
        "                     'color_intensity',\n",
        "                     'hue',\n",
        "                     'od280/od315_of_diluted_wines',\n",
        "                     'proline']\n",
        "\n",
        "    frame = None\n",
        "    target_columns = ['target', ]\n",
        "    if as_frame:\n",
        "        frame, data, target = _convert_data_dataframe(\"load_wine\",\n",
        "                                                      data,\n",
        "                                                      target,\n",
        "                                                      feature_names,\n",
        "                                                      target_columns)\n",
        "\n",
        "    if return_X_y:\n",
        "        return data, target\n",
        "\n",
        "    return Bunch(data=data,\n",
        "                 target=target,\n",
        "                 frame=frame,\n",
        "                 target_names=target_names,\n",
        "                 DESCR=fdescr,\n",
        "                 feature_names=feature_names)\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_iris(*, return_X_y=False, as_frame=False):\n",
        "    \"\"\"Load and return the iris dataset (classification).\n",
        "    The iris dataset is a classic and very easy multi-class classification\n",
        "    dataset.\n",
        "    =================   ==============\n",
        "    Classes                          3\n",
        "    Samples per class               50\n",
        "    Samples total                  150\n",
        "    Dimensionality                   4\n",
        "    Features            real, positive\n",
        "    =================   ==============\n",
        "    Read more in the :ref:`User Guide <iris_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    return_X_y : bool, default=False.\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object. See\n",
        "        below for more information about the `data` and `target` object.\n",
        "        .. versionadded:: 0.18\n",
        "    as_frame : bool, default=False\n",
        "        If True, the data is a pandas DataFrame including columns with\n",
        "        appropriate dtypes (numeric). The target is\n",
        "        a pandas DataFrame or Series depending on the number of target columns.\n",
        "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
        "        DataFrames or Series as described below.\n",
        "        .. versionadded:: 0.23\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : {ndarray, dataframe} of shape (150, 4)\n",
        "            The data matrix. If `as_frame=True`, `data` will be a pandas\n",
        "            DataFrame.\n",
        "        target: {ndarray, Series} of shape (150,)\n",
        "            The classification target. If `as_frame=True`, `target` will be\n",
        "            a pandas Series.\n",
        "        feature_names: list\n",
        "            The names of the dataset columns.\n",
        "        target_names: list\n",
        "            The names of target classes.\n",
        "        frame: DataFrame of shape (150, 5)\n",
        "            Only present when `as_frame=True`. DataFrame with `data` and\n",
        "            `target`.\n",
        "            .. versionadded:: 0.23\n",
        "        DESCR: str\n",
        "            The full description of the dataset.\n",
        "        filename: str\n",
        "            The path to the location of the data.\n",
        "            .. versionadded:: 0.20\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "        .. versionadded:: 0.18\n",
        "    Notes\n",
        "    -----\n",
        "        .. versionchanged:: 0.20\n",
        "            Fixed two wrong data points according to Fisher's paper.\n",
        "            The new version is the same as in R, but not as in the UCI\n",
        "            Machine Learning Repository.\n",
        "    Examples\n",
        "    --------\n",
        "    Let's say you are interested in the samples 10, 25, and 50, and want to\n",
        "    know their class name.\n",
        "    >>> from sklearn.datasets import load_iris\n",
        "    >>> data = load_iris()\n",
        "    >>> data.target[[10, 25, 50]]\n",
        "    array([0, 0, 1])\n",
        "    >>> list(data.target_names)\n",
        "    ['setosa', 'versicolor', 'virginica']\n",
        "    \"\"\"\n",
        "    module_path = dirname(__file__)\n",
        "    data, target, target_names = load_data(module_path, 'iris.csv')\n",
        "    iris_csv_filename = join(module_path, 'data', 'iris.csv')\n",
        "\n",
        "    with open(join(module_path, 'descr', 'iris.rst')) as rst_file:\n",
        "        fdescr = rst_file.read()\n",
        "\n",
        "    feature_names = ['sepal length (cm)', 'sepal width (cm)',\n",
        "                     'petal length (cm)', 'petal width (cm)']\n",
        "\n",
        "    frame = None\n",
        "    target_columns = ['target', ]\n",
        "    if as_frame:\n",
        "        frame, data, target = _convert_data_dataframe(\"load_iris\",\n",
        "                                                      data,\n",
        "                                                      target,\n",
        "                                                      feature_names,\n",
        "                                                      target_columns)\n",
        "\n",
        "    if return_X_y:\n",
        "        return data, target\n",
        "\n",
        "    return Bunch(data=data,\n",
        "                 target=target,\n",
        "                 frame=frame,\n",
        "                 target_names=target_names,\n",
        "                 DESCR=fdescr,\n",
        "                 feature_names=feature_names,\n",
        "                 filename=iris_csv_filename)\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_breast_cancer(*, return_X_y=False, as_frame=False):\n",
        "    \"\"\"Load and return the breast cancer wisconsin dataset (classification).\n",
        "    The breast cancer dataset is a classic and very easy binary classification\n",
        "    dataset.\n",
        "    =================   ==============\n",
        "    Classes                          2\n",
        "    Samples per class    212(M),357(B)\n",
        "    Samples total                  569\n",
        "    Dimensionality                  30\n",
        "    Features            real, positive\n",
        "    =================   ==============\n",
        "    Read more in the :ref:`User Guide <breast_cancer_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    return_X_y : bool, default=False\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
        "        See below for more information about the `data` and `target` object.\n",
        "        .. versionadded:: 0.18\n",
        "    as_frame : bool, default=False\n",
        "        If True, the data is a pandas DataFrame including columns with\n",
        "        appropriate dtypes (numeric). The target is\n",
        "        a pandas DataFrame or Series depending on the number of target columns.\n",
        "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
        "        DataFrames or Series as described below.\n",
        "        .. versionadded:: 0.23\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : {ndarray, dataframe} of shape (569, 30)\n",
        "            The data matrix. If `as_frame=True`, `data` will be a pandas\n",
        "            DataFrame.\n",
        "        target: {ndarray, Series} of shape (569,)\n",
        "            The classification target. If `as_frame=True`, `target` will be\n",
        "            a pandas Series.\n",
        "        feature_names: list\n",
        "            The names of the dataset columns.\n",
        "        target_names: list\n",
        "            The names of target classes.\n",
        "        frame: DataFrame of shape (569, 31)\n",
        "            Only present when `as_frame=True`. DataFrame with `data` and\n",
        "            `target`.\n",
        "            .. versionadded:: 0.23\n",
        "        DESCR: str\n",
        "            The full description of the dataset.\n",
        "        filename: str\n",
        "            The path to the location of the data.\n",
        "            .. versionadded:: 0.20\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "        .. versionadded:: 0.18\n",
        "    The copy of UCI ML Breast Cancer Wisconsin (Diagnostic) dataset is\n",
        "    downloaded from:\n",
        "    https://goo.gl/U2Uwz2\n",
        "    Examples\n",
        "    --------\n",
        "    Let's say you are interested in the samples 10, 50, and 85, and want to\n",
        "    know their class name.\n",
        "    >>> from sklearn.datasets import load_breast_cancer\n",
        "    >>> data = load_breast_cancer()\n",
        "    >>> data.target[[10, 50, 85]]\n",
        "    array([0, 1, 0])\n",
        "    >>> list(data.target_names)\n",
        "    ['malignant', 'benign']\n",
        "    \"\"\"\n",
        "    module_path = dirname(__file__)\n",
        "    data, target, target_names = load_data(module_path, 'breast_cancer.csv')\n",
        "    csv_filename = join(module_path, 'data', 'breast_cancer.csv')\n",
        "\n",
        "    with open(join(module_path, 'descr', 'breast_cancer.rst')) as rst_file:\n",
        "        fdescr = rst_file.read()\n",
        "\n",
        "    feature_names = np.array(['mean radius', 'mean texture',\n",
        "                              'mean perimeter', 'mean area',\n",
        "                              'mean smoothness', 'mean compactness',\n",
        "                              'mean concavity', 'mean concave points',\n",
        "                              'mean symmetry', 'mean fractal dimension',\n",
        "                              'radius error', 'texture error',\n",
        "                              'perimeter error', 'area error',\n",
        "                              'smoothness error', 'compactness error',\n",
        "                              'concavity error', 'concave points error',\n",
        "                              'symmetry error', 'fractal dimension error',\n",
        "                              'worst radius', 'worst texture',\n",
        "                              'worst perimeter', 'worst area',\n",
        "                              'worst smoothness', 'worst compactness',\n",
        "                              'worst concavity', 'worst concave points',\n",
        "                              'worst symmetry', 'worst fractal dimension'])\n",
        "\n",
        "    frame = None\n",
        "    target_columns = ['target', ]\n",
        "    if as_frame:\n",
        "        frame, data, target = _convert_data_dataframe(\"load_breast_cancer\",\n",
        "                                                      data,\n",
        "                                                      target,\n",
        "                                                      feature_names,\n",
        "                                                      target_columns)\n",
        "\n",
        "    if return_X_y:\n",
        "        return data, target\n",
        "\n",
        "    return Bunch(data=data,\n",
        "                 target=target,\n",
        "                 frame=frame,\n",
        "                 target_names=target_names,\n",
        "                 DESCR=fdescr,\n",
        "                 feature_names=feature_names,\n",
        "                 filename=csv_filename)\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_digits(*, n_class=10, return_X_y=False, as_frame=False):\n",
        "    \"\"\"Load and return the digits dataset (classification).\n",
        "    Each datapoint is a 8x8 image of a digit.\n",
        "    =================   ==============\n",
        "    Classes                         10\n",
        "    Samples per class             ~180\n",
        "    Samples total                 1797\n",
        "    Dimensionality                  64\n",
        "    Features             integers 0-16\n",
        "    =================   ==============\n",
        "    Read more in the :ref:`User Guide <digits_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_class : integer, between 0 and 10, optional (default=10)\n",
        "        The number of classes to return.\n",
        "    return_X_y : bool, default=False.\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
        "        See below for more information about the `data` and `target` object.\n",
        "        .. versionadded:: 0.18\n",
        "    as_frame : bool, default=False\n",
        "        If True, the data is a pandas DataFrame including columns with\n",
        "        appropriate dtypes (numeric). The target is\n",
        "        a pandas DataFrame or Series depending on the number of target columns.\n",
        "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
        "        DataFrames or Series as described below.\n",
        "        .. versionadded:: 0.23\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : {ndarray, dataframe} of shape (1797, 64)\n",
        "            The flattened data matrix. If `as_frame=True`, `data` will be\n",
        "            a pandas DataFrame.\n",
        "        target: {ndarray, Series} of shape (1797,)\n",
        "            The classification target. If `as_frame=True`, `target` will be\n",
        "            a pandas Series.\n",
        "        feature_names: list\n",
        "            The names of the dataset columns.\n",
        "        target_names: list\n",
        "            The names of target classes.\n",
        "            .. versionadded:: 0.20\n",
        "        frame: DataFrame of shape (1797, 65)\n",
        "            Only present when `as_frame=True`. DataFrame with `data` and\n",
        "            `target`.\n",
        "            .. versionadded:: 0.23\n",
        "        images: {ndarray} of shape (1797, 8, 8)\n",
        "            The raw image data.\n",
        "        DESCR: str\n",
        "            The full description of the dataset.\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "        .. versionadded:: 0.18\n",
        "    This is a copy of the test set of the UCI ML hand-written digits datasets\n",
        "    https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
        "    Examples\n",
        "    --------\n",
        "    To load the data and visualize the images::\n",
        "        >>> from sklearn.datasets import load_digits\n",
        "        >>> digits = load_digits()\n",
        "        >>> print(digits.data.shape)\n",
        "        (1797, 64)\n",
        "        >>> import matplotlib.pyplot as plt #doctest: +SKIP\n",
        "        >>> plt.gray() #doctest: +SKIP\n",
        "        >>> plt.matshow(digits.images[0]) #doctest: +SKIP\n",
        "        >>> plt.show() #doctest: +SKIP\n",
        "    \"\"\"\n",
        "    module_path = dirname(__file__)\n",
        "    data = np.loadtxt(join(module_path, 'data', 'digits.csv.gz'),\n",
        "                      delimiter=',')\n",
        "    with open(join(module_path, 'descr', 'digits.rst')) as f:\n",
        "        descr = f.read()\n",
        "    target = data[:, -1].astype(np.int, copy=False)\n",
        "    flat_data = data[:, :-1]\n",
        "    images = flat_data.view()\n",
        "    images.shape = (-1, 8, 8)\n",
        "\n",
        "    if n_class < 10:\n",
        "        idx = target < n_class\n",
        "        flat_data, target = flat_data[idx], target[idx]\n",
        "        images = images[idx]\n",
        "\n",
        "    feature_names = ['pixel_{}_{}'.format(row_idx, col_idx)\n",
        "                     for row_idx in range(8)\n",
        "                     for col_idx in range(8)]\n",
        "\n",
        "    frame = None\n",
        "    target_columns = ['target', ]\n",
        "    if as_frame:\n",
        "        frame, flat_data, target = _convert_data_dataframe(\"load_digits\",\n",
        "                                                           flat_data,\n",
        "                                                           target,\n",
        "                                                           feature_names,\n",
        "                                                           target_columns)\n",
        "\n",
        "    if return_X_y:\n",
        "        return flat_data, target\n",
        "\n",
        "    return Bunch(data=flat_data,\n",
        "                 target=target,\n",
        "                 frame=frame,\n",
        "                 feature_names=feature_names,\n",
        "                 target_names=np.arange(10),\n",
        "                 images=images,\n",
        "                 DESCR=descr)\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_diabetes(*, return_X_y=False, as_frame=False):\n",
        "    \"\"\"Load and return the diabetes dataset (regression).\n",
        "    ==============   ==================\n",
        "    Samples total    442\n",
        "    Dimensionality   10\n",
        "    Features         real, -.2 < x < .2\n",
        "    Targets          integer 25 - 346\n",
        "    ==============   ==================\n",
        "    Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    return_X_y : bool, default=False.\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
        "        See below for more information about the `data` and `target` object.\n",
        "        .. versionadded:: 0.18\n",
        "    as_frame : bool, default=False\n",
        "        If True, the data is a pandas DataFrame including columns with\n",
        "        appropriate dtypes (numeric). The target is\n",
        "        a pandas DataFrame or Series depending on the number of target columns.\n",
        "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
        "        DataFrames or Series as described below.\n",
        "        .. versionadded:: 0.23\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : {ndarray, dataframe} of shape (442, 10)\n",
        "            The data matrix. If `as_frame=True`, `data` will be a pandas\n",
        "            DataFrame.\n",
        "        target: {ndarray, Series} of shape (442,)\n",
        "            The regression target. If `as_frame=True`, `target` will be\n",
        "            a pandas Series.\n",
        "        feature_names: list\n",
        "            The names of the dataset columns.\n",
        "        frame: DataFrame of shape (442, 11)\n",
        "            Only present when `as_frame=True`. DataFrame with `data` and\n",
        "            `target`.\n",
        "            .. versionadded:: 0.23\n",
        "        DESCR: str\n",
        "            The full description of the dataset.\n",
        "        data_filename: str\n",
        "            The path to the location of the data.\n",
        "        target_filename: str\n",
        "            The path to the location of the target.\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "        .. versionadded:: 0.18\n",
        "    \"\"\"\n",
        "    module_path = dirname(__file__)\n",
        "    base_dir = join(module_path, 'data')\n",
        "    data_filename = join(base_dir, 'diabetes_data.csv.gz')\n",
        "    data = np.loadtxt(data_filename)\n",
        "    target_filename = join(base_dir, 'diabetes_target.csv.gz')\n",
        "    target = np.loadtxt(target_filename)\n",
        "\n",
        "    with open(join(module_path, 'descr', 'diabetes.rst')) as rst_file:\n",
        "        fdescr = rst_file.read()\n",
        "\n",
        "    feature_names = ['age', 'sex', 'bmi', 'bp',\n",
        "                     's1', 's2', 's3', 's4', 's5', 's6']\n",
        "\n",
        "    frame = None\n",
        "    target_columns = ['target', ]\n",
        "    if as_frame:\n",
        "        frame, data, target = _convert_data_dataframe(\"load_diabetes\",\n",
        "                                                      data,\n",
        "                                                      target,\n",
        "                                                      feature_names,\n",
        "                                                      target_columns)\n",
        "\n",
        "    if return_X_y:\n",
        "        return data, target\n",
        "\n",
        "    return Bunch(data=data,\n",
        "                 target=target,\n",
        "                 frame=frame,\n",
        "                 DESCR=fdescr,\n",
        "                 feature_names=feature_names,\n",
        "                 data_filename=data_filename,\n",
        "                 target_filename=target_filename)\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_linnerud(*, return_X_y=False, as_frame=False):\n",
        "    \"\"\"Load and return the physical excercise linnerud dataset.\n",
        "    This dataset is suitable for multi-ouput regression tasks.\n",
        "    ==============   ============================\n",
        "    Samples total    20\n",
        "    Dimensionality   3 (for both data and target)\n",
        "    Features         integer\n",
        "    Targets          integer\n",
        "    ==============   ============================\n",
        "    Read more in the :ref:`User Guide <linnerrud_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    return_X_y : bool, default=False.\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
        "        See below for more information about the `data` and `target` object.\n",
        "        .. versionadded:: 0.18\n",
        "    as_frame : bool, default=False\n",
        "        If True, the data is a pandas DataFrame including columns with\n",
        "        appropriate dtypes (numeric, string or categorical). The target is\n",
        "        a pandas DataFrame or Series depending on the number of target columns.\n",
        "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
        "        DataFrames or Series as described below.\n",
        "        .. versionadded:: 0.23\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : {ndarray, dataframe} of shape (20, 3)\n",
        "            The data matrix. If `as_frame=True`, `data` will be a pandas\n",
        "            DataFrame.\n",
        "        target: {ndarray, dataframe} of shape (20, 3)\n",
        "            The regression targets. If `as_frame=True`, `target` will be\n",
        "            a pandas DataFrame.\n",
        "        feature_names: list\n",
        "            The names of the dataset columns.\n",
        "        target_names: list\n",
        "            The names of the target columns.\n",
        "        frame: DataFrame of shape (20, 6)\n",
        "            Only present when `as_frame=True`. DataFrame with `data` and\n",
        "            `target`.\n",
        "            .. versionadded:: 0.23\n",
        "        DESCR: str\n",
        "            The full description of the dataset.\n",
        "        data_filename: str\n",
        "            The path to the location of the data.\n",
        "        target_filename: str\n",
        "            The path to the location of the target.\n",
        "            .. versionadded:: 0.20\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "        .. versionadded:: 0.18\n",
        "    \"\"\"\n",
        "    base_dir = join(dirname(__file__), 'data/')\n",
        "    data_filename = join(base_dir, 'linnerud_exercise.csv')\n",
        "    target_filename = join(base_dir, 'linnerud_physiological.csv')\n",
        "\n",
        "    # Read data\n",
        "    data_exercise = np.loadtxt(data_filename, skiprows=1)\n",
        "    data_physiological = np.loadtxt(target_filename, skiprows=1)\n",
        "\n",
        "    # Read header\n",
        "    with open(data_filename) as f:\n",
        "        header_exercise = f.readline().split()\n",
        "    with open(target_filename) as f:\n",
        "        header_physiological = f.readline().split()\n",
        "\n",
        "    with open(dirname(__file__) + '/descr/linnerud.rst') as f:\n",
        "        descr = f.read()\n",
        "\n",
        "    frame = None\n",
        "    if as_frame:\n",
        "        (frame,\n",
        "         data_exercise,\n",
        "         data_physiological) = _convert_data_dataframe(\"load_linnerud\",\n",
        "                                                       data_exercise,\n",
        "                                                       data_physiological,\n",
        "                                                       header_exercise,\n",
        "                                                       header_physiological)\n",
        "    if return_X_y:\n",
        "        return data_exercise, data_physiological\n",
        "\n",
        "    return Bunch(data=data_exercise,\n",
        "                 feature_names=header_exercise,\n",
        "                 target=data_physiological,\n",
        "                 target_names=header_physiological,\n",
        "                 frame=frame,\n",
        "                 DESCR=descr,\n",
        "                 data_filename=data_filename,\n",
        "                 target_filename=target_filename)\n",
        "\n",
        "\n",
        "@_deprecate_positional_args\n",
        "def load_boston(*, return_X_y=False):\n",
        "    \"\"\"Load and return the boston house-prices dataset (regression).\n",
        "    ==============   ==============\n",
        "    Samples total               506\n",
        "    Dimensionality               13\n",
        "    Features         real, positive\n",
        "    Targets           real 5. - 50.\n",
        "    ==============   ==============\n",
        "    Read more in the :ref:`User Guide <boston_dataset>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    return_X_y : bool, default=False.\n",
        "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
        "        See below for more information about the `data` and `target` object.\n",
        "        .. versionadded:: 0.18\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        data : ndarray of shape (506, 13)\n",
        "            The data matrix.\n",
        "        target : ndarray of shape (506, )\n",
        "            The regression target.\n",
        "        filename : str\n",
        "            The physical location of boston csv dataset.\n",
        "            .. versionadded:: 0.20\n",
        "        DESCR : str\n",
        "            The full description of the dataset.\n",
        "        feature_names : ndarray\n",
        "            The names of features\n",
        "    (data, target) : tuple if ``return_X_y`` is True\n",
        "        .. versionadded:: 0.18\n",
        "    Notes\n",
        "    -----\n",
        "        .. versionchanged:: 0.20\n",
        "            Fixed a wrong data point at [445, 0].\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from sklearn.datasets import load_boston\n",
        "    >>> X, y = load_boston(return_X_y=True)\n",
        "    >>> print(X.shape)\n",
        "    (506, 13)\n",
        "    \"\"\"\n",
        "    module_path = dirname(__file__)\n",
        "\n",
        "    fdescr_name = join(module_path, 'descr', 'boston_house_prices.rst')\n",
        "    with open(fdescr_name) as f:\n",
        "        descr_text = f.read()\n",
        "\n",
        "    data_file_name = join(module_path, 'data', 'boston_house_prices.csv')\n",
        "    with open(data_file_name) as f:\n",
        "        data_file = csv.reader(f)\n",
        "        temp = next(data_file)\n",
        "        n_samples = int(temp[0])\n",
        "        n_features = int(temp[1])\n",
        "        data = np.empty((n_samples, n_features))\n",
        "        target = np.empty((n_samples,))\n",
        "        temp = next(data_file)  # names of features\n",
        "        feature_names = np.array(temp)\n",
        "\n",
        "        for i, d in enumerate(data_file):\n",
        "            data[i] = np.asarray(d[:-1], dtype=np.float64)\n",
        "            target[i] = np.asarray(d[-1], dtype=np.float64)\n",
        "\n",
        "    if return_X_y:\n",
        "        return data, target\n",
        "\n",
        "    return Bunch(data=data,\n",
        "                 target=target,\n",
        "                 # last column is target value\n",
        "                 feature_names=feature_names[:-1],\n",
        "                 DESCR=descr_text,\n",
        "                 filename=data_file_name)\n",
        "\n",
        "\n",
        "def load_sample_images():\n",
        "    \"\"\"Load sample images for image manipulation.\n",
        "    Loads both, ``china`` and ``flower``.\n",
        "    Read more in the :ref:`User Guide <sample_images>`.\n",
        "    Returns\n",
        "    -------\n",
        "    data : :class:`~sklearn.utils.Bunch`\n",
        "        Dictionary-like object, with the following attributes.\n",
        "        images : list of ndarray of shape (427, 640, 3)\n",
        "            The two sample image.\n",
        "        filenames : list\n",
        "            The filenames for the images.\n",
        "        DESCR : str\n",
        "            The full description of the dataset.\n",
        "    Examples\n",
        "    --------\n",
        "    To load the data and visualize the images:\n",
        "    >>> from sklearn.datasets import load_sample_images\n",
        "    >>> dataset = load_sample_images()     #doctest: +SKIP\n",
        "    >>> len(dataset.images)                #doctest: +SKIP\n",
        "    2\n",
        "    >>> first_img_data = dataset.images[0] #doctest: +SKIP\n",
        "    >>> first_img_data.shape               #doctest: +SKIP\n",
        "    (427, 640, 3)\n",
        "    >>> first_img_data.dtype               #doctest: +SKIP\n",
        "    dtype('uint8')\n",
        "    \"\"\"\n",
        "    # import PIL only when needed\n",
        "    from ..externals._pilutil import imread\n",
        "\n",
        "    module_path = join(dirname(__file__), \"images\")\n",
        "    with open(join(module_path, 'README.txt')) as f:\n",
        "        descr = f.read()\n",
        "    filenames = [join(module_path, filename)\n",
        "                 for filename in sorted(os.listdir(module_path))\n",
        "                 if filename.endswith(\".jpg\")]\n",
        "    # Load image data for each image in the source folder.\n",
        "    images = [imread(filename) for filename in filenames]\n",
        "\n",
        "    return Bunch(images=images,\n",
        "                 filenames=filenames,\n",
        "                 DESCR=descr)\n",
        "\n",
        "\n",
        "def load_sample_image(image_name):\n",
        "    \"\"\"Load the numpy array of a single sample image\n",
        "    Read more in the :ref:`User Guide <sample_images>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    image_name : {`china.jpg`, `flower.jpg`}\n",
        "        The name of the sample image loaded\n",
        "    Returns\n",
        "    -------\n",
        "    img : 3D array\n",
        "        The image as a numpy array: height x width x color\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from sklearn.datasets import load_sample_image\n",
        "    >>> china = load_sample_image('china.jpg')   # doctest: +SKIP\n",
        "    >>> china.dtype                              # doctest: +SKIP\n",
        "    dtype('uint8')\n",
        "    >>> china.shape                              # doctest: +SKIP\n",
        "    (427, 640, 3)\n",
        "    >>> flower = load_sample_image('flower.jpg') # doctest: +SKIP\n",
        "    >>> flower.dtype                             # doctest: +SKIP\n",
        "    dtype('uint8')\n",
        "    >>> flower.shape                             # doctest: +SKIP\n",
        "    (427, 640, 3)\n",
        "    \"\"\"\n",
        "    images = load_sample_images()\n",
        "    index = None\n",
        "    for i, filename in enumerate(images.filenames):\n",
        "        if filename.endswith(image_name):\n",
        "            index = i\n",
        "            break\n",
        "    if index is None:\n",
        "        raise AttributeError(\"Cannot find sample image: %s\" % image_name)\n",
        "    return images.images[index]\n",
        "\n",
        "\n",
        "def _pkl_filepath(*args, **kwargs):\n",
        "    \"\"\"Return filename for Python 3 pickles\n",
        "    args[-1] is expected to be the \".pkl\" filename. For compatibility with\n",
        "    older scikit-learn versions, a suffix is inserted before the extension.\n",
        "    _pkl_filepath('/path/to/folder', 'filename.pkl') returns\n",
        "    '/path/to/folder/filename_py3.pkl'\n",
        "    \"\"\"\n",
        "    py3_suffix = kwargs.get(\"py3_suffix\", \"_py3\")\n",
        "    basename, ext = splitext(args[-1])\n",
        "    basename += py3_suffix\n",
        "    new_args = args[:-1] + (basename + ext,)\n",
        "    return join(*new_args)\n",
        "\n",
        "\n",
        "def _sha256(path):\n",
        "    \"\"\"Calculate the sha256 hash of the file at path.\"\"\"\n",
        "    sha256hash = hashlib.sha256()\n",
        "    chunk_size = 8192\n",
        "    with open(path, \"rb\") as f:\n",
        "        while True:\n",
        "            buffer = f.read(chunk_size)\n",
        "            if not buffer:\n",
        "                break\n",
        "            sha256hash.update(buffer)\n",
        "    return sha256hash.hexdigest()\n",
        "\n",
        "\n",
        "def _fetch_remote(remote, dirname=None):\n",
        "    \"\"\"Helper function to download a remote dataset into path\n",
        "    Fetch a dataset pointed by remote's url, save into path using remote's\n",
        "    filename and ensure its integrity based on the SHA256 Checksum of the\n",
        "    downloaded file.\n",
        "    Parameters\n",
        "    ----------\n",
        "    remote : RemoteFileMetadata\n",
        "        Named tuple containing remote dataset meta information: url, filename\n",
        "        and checksum\n",
        "    dirname : string\n",
        "        Directory to save the file to.\n",
        "    Returns\n",
        "    -------\n",
        "    file_path: string\n",
        "        Full path of the created file.\n",
        "    \"\"\"\n",
        "\n",
        "    file_path = (remote.filename if dirname is None\n",
        "                 else join(dirname, remote.filename))\n",
        "    urlretrieve(remote.url, file_path)\n",
        "    checksum = _sha256(file_path)\n",
        "    if remote.checksum != checksum:\n",
        "        raise IOError(\"{} has an SHA256 checksum ({}) \"\n",
        "                      \"differing from expected ({}), \"\n",
        "                      \"file may be corrupted.\".format(file_path, checksum,\n",
        "                                                      remote.checksum))\n",
        "    return file_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8fb0c70722d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_pandas_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
          ]
        }
      ]
    }
  ]
}